#!/bin/bash
#SBATCH -A pccr
#SBATCH -t 2:00:00
#SBATCH -N 1
#SBATCH -n 30
#SBATCH --job-name=combine_matrix


#SBATCH --error=%x-%J-%u.err
#SBATCH --output=%x-%J-%u.out

starts=$(date +"%s")
start=$(date +"%r, %m-%d-%Y")

module --force purge
module load biocontainers
module load csvtk

cd /depot/tlratlif/data/Gada_data/2024_4_Gada_SMC_RNA_Bulk/30-994315926/Output/COUNTS/
############ MERGE QUANTIFICATIONS ##############
# we use the tool csvtk's join function. It allows us to use arbitrarily large number of files compared to unix join
# -t -> specifies both inputs and output will be tab-delimited
# sed -> we are using stream editing to remove the .Aligned.sortedByCoord.out.bam to keep the name simple via pattern matching. 
# the counts file contains columns  in the format Sample1.Aligned.sortedByCoord.out.bam and so on, we want this to be just Sample1.
# similarly, we replace Geneid to Gene_ID since downstream scripts/pipelines contain the column with the header value Gene_ID
################################################
csvtk join -t $(ls *.counts) | sed 's/.Aligned.sortedByCoord.out.bam//g' | sed 's/Geneid/Gene_ID/g' > combined_counts.tsv
cp combined_counts.tsv ../Diffexp

ends=$(date +"%s")
end=$(date +"%r, %m-%d-%Y")
diff=$(($ends-$starts))
hours=$(($diff / 3600))
dif=$(($diff % 3600))
minutes=$(($dif / 60))
seconds=$(($dif % 60))
printf "\n\t===========Time Stamp===========\n"
printf "\tStart\t:$start\n\tEnd\t:$end\n\tTime\t:%02d:%02d:%02d\n" "$hours" "$minutes" "$seconds"
printf "\t================================\n\n"

sacct --jobs=$SLURM_JOBID --format=jobid,jobname,qos,nnodes,ncpu,maxrss,cputime,avecpu,elapsed

